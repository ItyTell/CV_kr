{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 1"
      ],
      "metadata": {
        "id": "E8kL2ayGpCPT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xe4dxquo1MU"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Load images\n",
        "gt_image = cv2.imread(\"<path to ground truth image>\")\n",
        "\n",
        "target_image_1 = cv2.imread(\"<path to target image>\")\n",
        "target_image_2 = cv2.imread(\"<path to target image>\")\n",
        "target_image_3 = cv2.imread(\"<path to target image>\")\n",
        "target_image_4 = cv2.imread(\"<path to target image>\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_METADATA = r\"/content/metadata.txt\"\n",
        "\n",
        "gt_values = {}\n",
        "for line in open(PATH_METADATA, \"r\"):\n",
        "  name, value = line.split(\" - \")\n",
        "  gt_values[name] = float(value)"
      ],
      "metadata": {
        "id": "KIPh6T19qiss"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimated_distances = {}\n",
        "\n",
        "# Solution\n",
        "# ...."
      ],
      "metadata": {
        "id": "MvpUCG3ArhZf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric calculation\n",
        "\n",
        "avarage_dist_error = 0.0\n",
        "\n",
        "for name, estmated_dist in estimated_distances.items():\n",
        "  avarage_dist_error += (estmated_dist - gt_values[name])\n",
        "\n",
        "avarage_dist = avarage_dist_error / 4.0\n",
        "\n",
        "print(\"Avarage distance error: \", avarage_dist_error)"
      ],
      "metadata": {
        "id": "-WszI16KrlJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Завдання 2\n"
      ],
      "metadata": {
        "id": "zWiMh4l7pHvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "# Create Cifar100Subset\n",
        "\n",
        "class Cifar100Subset(Dataset):\n",
        "\n",
        "    def __init__(self, sub_classes, root, train=True, transform=None, download=False):\n",
        "\n",
        "        self.dataset = datasets.CIFAR100(root=root, train=train, transform=transform, download=download)\n",
        "        self.sub_classes = sub_classes\n",
        "        self.sub_classes_indices = []\n",
        "\n",
        "        for name in self.sub_classes:\n",
        "            self.sub_classes_indices.append(self.dataset.class_to_idx[name])\n",
        "\n",
        "        self.target_indices = [i for i, target in enumerate(self.dataset.targets) if target in self.sub_classes_indices]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_indices)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index = self.target_indices[index]\n",
        "        return self.dataset[index]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "sub_classes = []\n",
        "\n",
        "cifar100_train = Cifar100Subset(sub_classes=sub_classes, root='./data', train=True, transform=transform, download=True)\n",
        "cifar100_test = Cifar100Subset(sub_classes=sub_classes, root='./data', train=False, transform=transform, download=True)"
      ],
      "metadata": {
        "id": "o_VbhbjnpLLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Traning pipeline\n",
        "# ....\n",
        "\n",
        "\n",
        "# torch.save(best_model.state_dict(), 'best_model.pth')"
      ],
      "metadata": {
        "id": "s7xzqmVjxBCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "\n",
        "def load_model(model, path):\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    return model\n",
        "\n",
        "model = load_model(model, 'best_model.pth')\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(cifar100_test, batch_size=1, shuffle=False)\n",
        "\n",
        "for data in testloader:\n",
        "    images, labels = data\n",
        "    output = model(images)[0]\n",
        "\n",
        "    pred_class_id = cifar100_test.sub_classes_indices[int(torch.argmax(output))]\n",
        "\n",
        "    correct += (pred_class_id == labels)\n",
        "    total += 1\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "v_CrC8btxj4O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}